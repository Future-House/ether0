{"id":"b26017b3-9b6b-4879-910a-acbcf58f1ba5","question":"What constraints do FUNCTIONAL_GROUP_PROMPTS place on molecular generation?","answer":"FUNCTIONAL_GROUP_PROMPTS (6 variations) require models to generate SMILES structures that contain specific functional groups and match exact molecular formulas. Examples include 'Propose a compound with molecular formula {formula} that contains the following functional groups: {functional_group}' and 'Generate a SMILES representation for a molecule containing groups: {functional_group}. It should also have formula {formula}.' This tests the model's ability to satisfy multiple structural constraints simultaneously."}
{"id":"04060986-f4b3-4b8e-91ec-a7e9c6fa01bc","question":"What is the purpose of the wrap_reward_func function in ether0's chat module?","answer":"The `wrap_reward_func()` function wraps reward functions with additional keyword arguments while preserving the original function's metadata using `@wraps(func)`. This is needed by GRPOTrainer for logging purposes. It takes a callable function and additional wrap_kwargs, returning a wrapped function that calls the original with both the passed arguments and the wrapped keyword arguments."}
{"id":"07e53770-86a4-493e-a362-9557a9f21ea2","question":"What is the oracle_rxn_eval function and how does it validate chemical reactions?","answer":"The `oracle_rxn_eval()` function validates chemical reactions by: 1) Checking the reaction SMILES format contains '>' and '.' with proper structure, 2) Validating all reactants, reagents, and products are valid molecules, 3) Ensuring the desired product doesn't appear in reactants\/reagents, 4) Verifying reactants are commercially purchasable using `fetch_purchasable()`, 5) Using `fetch_forward_rxn()` API to predict the actual product, 6) Comparing predicted vs. expected products with exact match (hard) or Tanimoto similarity (soft). It returns 1.0 for valid reactions and 0.0 for failures."}
{"id":"d2dc6f5b-7c16-4689-9a5f-19c49d7dc9ed","question":"What is the purpose and structure of COMPLETE_MOL_PROMPTS in ether0?","answer":"COMPLETE_MOL_PROMPTS contains 10 prompt variations for molecular completion tasks, where models must complete partial SMILES strings. Examples include 'I have a partial molecule represented by the SMILES string {smiles}. What is a valid completion of this molecule, providing only the remaining characters in SMILES format?' These prompts specifically request only the additional SMILES characters needed to complete the molecule, not the full structure."}
{"id":"5987c880-c592-429b-838d-d282f8926ff3","question":"What is the purpose of LOOSE_XML_ANSWER_USER_PROMPT in ether0's model prompts?","answer":"The `LOOSE_XML_ANSWER_USER_PROMPT` is a user-facing instruction that tells models to place their final answer in XML tags `<answer><\/answer>` with SMILES notation. It provides an example: `<answer>CCO<\/answer>`. This prompt is used with models that haven't been specifically trained on ether0's XML format to guide them toward the expected response structure for proper answer extraction."}
{"id":"55d5cd65-4541-40fd-a9c3-7c9daac3d340","question":"What molecular validation checks does ether0 perform and how do they work together?","answer":"ether0 performs two main molecular validation checks: 1) Ring system validation using `is_reasonable_ring_system()` which extracts ring systems, canonicalizes them, and checks against a bloom filter of known rings, optionally excluding reference molecule rings. 2) Fingerprint validation using `is_reasonable_fp()` which computes Morgan fingerprint bits and validates them against a fingerprint bloom filter. Both functions can accept reference molecules to exclude known-good patterns from validation."}
{"id":"c63877bc-2924-4115-a7e1-460c5b54f7af","question":"What bad substructure patterns does ether0 check for and why?","answer":"ether0 checks for bad substructure patterns using BAD_SMARTS_PATTERNS including: sulfur chains ([#16]-[#16]-[#16]), peroxides ([#8]~[#8]), hydrazines ([#7]-[NH2]), weird charged amines ([#7]-[NH3]), chains of 3+ amines ([#7]~[#7]~[#7]), nitrites, thionitrites, nitrates, nitro groups, nitroso groups, and long carbon chains (7+ carbons). These patterns identify chemically unstable, toxic, or synthetically implausible structures that should receive penalty during training through the `contains_bad_substruct()` function."}
{"id":"6b36bcce-6138-41dc-a444-ef03a751c5f4","question":"What are the two XMLAnswerPrompts enum values and their purposes?","answer":"The two XMLAnswerPrompts enum values are: 1) `REASONING_ANSWER`: Prompts the model to provide both reasoning process and answer, with reasoning in `<|think_start|>` `<|think_end|>` tags and answer in `<|answer_start|>` `<|answer_end|>` tags. 2) `ANSWER_ONLY`: Prompts the model to provide only the answer enclosed in `<|answer_start|>` `<|answer_end|>` tags without reasoning. Each has a corresponding strict regex pattern for parsing responses."}
{"id":"c675be90-5d30-46e4-b018-0a016e952cf6","question":"What are the key components of ether0's training methodology for specialists vs generalists?","answer":"ether0 creates specialists through focused RLVR training on specific task groups, allowing models to learn at their own pace. These specialists are then filtered through rejection sampling for correctness and quality. The generalist model is created by doing SFT on the base model using the filtered specialist reasoning traces. Finally, RLVR is applied to the generalist to recover any lost performance and push further in an all-task setting."}
{"id":"29d19e84-b9ea-42c5-9947-2109775d753a","question":"What are the five main phases in ether0's training loop?","answer":"1. Supervised fine-tuning (SFT) on long chain-of-thought reasoning traces\n2. Reinforcement learning with verifiable rewards (RLVR) to create specialists\n3. Rejection sampling to filter specialists' reasoning\n4. SFT on the base model again to make a generalist\n5. RLVR to recover performance and push further in an all-task setting"}
{"id":"20de3d1a-2329-4351-b348-621cccab2bb0","question":"What types of prompts are available for IUPAC name and SMILES conversion tasks in ether0?","answer":"ether0 provides two complementary prompt sets: NAME_IUPAC_PROMPTS (10 variations) for converting IUPAC names to SMILES, asking questions like 'What are the SMILES from the IUPAC name: {iupac}?', and NAME_SMILES_PROMPTS (10 variations) for converting SMILES to IUPAC names, asking questions like 'What is the IUPAC name of this molecule: {smiles}?'. Both sets provide diverse phrasings to avoid model overfitting to specific question formats."}
{"id":"925ffd17-6e8a-4eeb-b623-bade279372c3","question":"What reward functions are returned by ChatArguments.get_reward_funcs() and what parameters do they accept?","answer":"The method returns two wrapped reward functions: 1) `format_reward`: Wrapped with reasoning and reward parameters, checking if the response follows proper XML formatting. 2) `accuracy_reward`: Wrapped with reasoning, soft, test, and good_molecule_bonus parameters, evaluating the correctness of the answer. The wrapping uses `wrap_reward_func()` to inject additional parameters like the reasoning mode, reward values, and evaluation settings."}
{"id":"28fd7853-ae94-404d-a210-66529adc1776","question":"How does the normalize_iupac function handle chemical name standardization?","answer":"The `normalize_iupac()` function standardizes chemical names by: 1) Converting to lowercase and stripping whitespace, 2) Replacing superscript patterns `^{n}` with `^(n)`, 3) Removing italicized text patterns `{letter}`, 4) Removing special characters like `$` and `~`, 5) Converting useless parentheses patterns to hyphens, 6) Removing carets and replacing spaces with hyphens. This normalization allows fuzzy matching of IUPAC names that may have different formatting conventions while preserving chemical meaning."}
{"id":"e8fa60d3-64e8-4df7-a6e9-87a737a10279","question":"What is the purpose of fingerprint validation in ether0's molecular processing?","answer":"Fingerprint validation uses Morgan fingerprints to assess molecular reasonableness. The `_get_bits()` function extracts fingerprint bits from molecules, and `is_reasonable_fp()` checks if these bits exist in a precomputed bloom filter of known molecular fingerprints. This helps identify unrealistic or chemically implausible molecular structures by comparing against a database of reasonable molecular patterns."}
{"id":"90541c47-edf4-4787-a1eb-4fe726b40d73","question":"What are the key differences between make_rl_conversation and make_sft_conversation in ChatArguments?","answer":"The key differences are: 1) `make_rl_conversation()` creates conversations for reinforcement learning without including the answer, returning a `prompt` key, while `make_sft_conversation()` includes both the problem and answer for supervised fine-tuning, returning a `messages` key. 2) SFT conversations include the assistant's response with optional thinking and answer enclosed in XML tags, while RL conversations only include the user's prompt. 3) SFT validates that reasoning and ANSWER-only prompts are not mixed."}
{"id":"1af8b2ce-3fa3-4e52-be25-fcbfaedd17a2","question":"How do you visualize a molecule using ether0's drawing functions?","answer":"Use the `draw_molecule()` function with a SMILES string: `from ether0.data import draw_molecule; valid_mol_text = draw_molecule(smiles_string)`. The function returns SVG text that can be saved to a file or displayed. For terminal visualization, you can use chafa: `chafa valid_molecule.svg`. The function internally uses RDKit to convert SMILES to molecules, compute 2D coordinates, and create SVG drawings."}
{"id":"6dc5066e-acb2-4733-978d-461907a84cbc","question":"How are categorical property predictions structured in PROPERTY_PROMPTS_CAT?","answer":"PROPERTY_PROMPTS_CAT contains 9 prompt variations for identifying molecules with categorical properties from multiple choice options. The prompts use formats like 'Which of the following options likely is{rel} a {property} molecule?' and 'Which of the following molecules is likely to{rel} be {property}?' where {rel} can be empty or ' not' to handle both positive and negative property identification. This allows testing both directions of categorical classification."}
{"id":"37455607-7ac1-4e62-bd81-d908a3c43a58","question":"How does the get_largest_mol function handle complex SMILES with multiple components?","answer":"The `get_largest_mol()` function processes multi-component SMILES by: 1) Splitting on '.' to separate fragments, 2) Filtering out small fragments (\u22643 characters) and invalid SMILES, 3) Converting valid fragments to RDKit molecules, 4) Counting atoms for each valid molecule, 5) Returning the molecule with the maximum atom count. This effectively removes counterions, salts, and solvents while preserving the main molecular structure for evaluation purposes."}
{"id":"6c713cd7-cf6a-4695-ab8e-661b92ff59d6","question":"What is the RewardFunctionInfo data model and how does it serialize problem metadata?","answer":"RewardFunctionInfo is a Pydantic model that encapsulates reward function metadata with fields: `fxn_name` (reward function name), `answer_info` (serialized metadata for evaluation), and `problem_type` (for reference). It supports deserialization from string format using SOLUTION_DELIMITER ('!:!') to split a 3-tuple string into these components. This model is used in QAExample to specify which evaluation function to use and provide the necessary parameters for answer validation."}
{"id":"a4516ad8-2acf-42ab-968c-379592804b34","question":"What regex pattern is used to extract SMILES strings from text in ether0?","answer":"The SMILES_PATTERN regex is: `r\"(?<!\\w)(?:(?:Cl|Br|[BCNOPSFIC]|[cnops]|\\[[^\\]]+?\\]|[0-9@+\\-=#\\\\\/()%])){4,}(?!\\w)\"`. This pattern matches chemical element symbols, brackets for complex atoms, and chemical notation characters with a minimum length of 4 characters. Note that it currently fails on counterions like `Cc1ccc(-c2ccc3c(c2)c2ccccc2c[n+]3C)cc1.[Cl-]`."}
{"id":"0c45f458-fbdf-4616-bd41-c803f1c2cc47","question":"What environment variables and configuration does ether0's client system use?","answer":"ether0's client system uses several environment variables: 1) `ETHER0_REMOTES_API_BASE_URL` for the server endpoint, 2) `ETHER0_REMOTES_API_TOKEN` for authentication, 3) `ETHER0_REMOTES_THROW_500_ERROR_THRESHOLD` (default 100) for error handling, 4) Configuration includes REMOTE_WORKER_COLD_START_TIME (180 sec) timeout, 5) SERVER_ERRORS_COUNTER tracks failures per endpoint, 6) Headers include Authorization Bearer token and Content-Type application\/json. The system gracefully handles cold starts and implements exponential backoff for reliability."}
{"id":"259228a3-eb5e-4d12-98d9-254ce4983dd9","question":"How are bloom filters used in ether0's molecular validation?","answer":"Bloom filters are used in two validation functions: `is_reasonable_ring_system()` uses a 'rings' bloom filter to check if extracted ring systems are found in known rings, and `is_reasonable_fp()` uses a 'fingerprints' bloom filter to validate Morgan fingerprint bits. The filters are loaded from files named '{name}.bloom' in the ether0 directory and cached in a global dictionary for efficiency."}
{"id":"c5843e23-bff6-4688-8ab6-28c43c06eada","question":"What is the difference between PROPERTY_TRIPLET_PROMPTS and PROPERTY_TRIPLET_PROMPTS_CAT?","answer":"PROPERTY_TRIPLET_PROMPTS (10 variations) deals with continuous numerical properties, asking which molecule would {change} a property like 'I have a molecule {smiles1} with a {property} of {value1}. Which of these similar molecules will most likely {change} this property?' PROPERTY_TRIPLET_PROMPTS_CAT (8 variations) handles categorical properties, using phrasing like 'I have a molecule {smiles1} which {rel} {property}. Which of these similar molecules will most likely {irel} this property?' where {rel} and {irel} are categorical relationships."}
{"id":"35c1903f-b6f4-4c68-beb1-de4e6058c636","question":"How does the formula_diff function calculate molecular formula differences?","answer":"The `formula_diff()` function calculates the L2 norm between molecular formulas by: 1) Defining important organic chemistry elements (C, H, O, N, F, Cl, Br, P, S), 2) Using regex to parse element-count pairs from both formulas, 3) Creating count dictionaries initialized to 0 for all important elements, 4) Summing element counts for each formula, 5) Computing the L2 distance as sqrt(sum((counts1[k] - counts2[k])^2)) across all important elements. This provides a quantitative measure of how different two molecular formulas are in terms of atomic composition."}
{"id":"c3229fef-8c98-487f-82ac-0de646c7cf16","question":"What is the purpose of the EVAL_FUNCTIONS mapping and what functions does it contain?","answer":"The EVAL_FUNCTIONS mapping serves as a registry of reward evaluation functions, containing: `str_eval` (string comparison), `valid_mol_eval` (molecule validity), `caption_eval` (molecule captioning), `product_eval` (product comparison), `rxn_eval` (reaction name matching), `formula_eval` (formula validation), `functional_group_eval` (functional group matching), `sol_eval` (solubility evaluation), `rxn_forward` (forward reaction prediction), `should_not_answer_eval` (negative cases), and `should_answer_eval` (positive molecule cases). This mapping allows dynamic function selection during evaluation based on problem type."}
{"id":"0db1ab58-df25-4c8d-bc29-f43b9bc8e73c","question":"What specific Unicode normalization steps does the `normalize_unicodes()` function perform to handle dash characters and punctuation in chemical names?","answer":"ether0 handles Unicode through `normalize_unicodes()` which: 1) Applies NFKC normalization to standardize Unicode characters, 2) Converts all dashes and punctuation (categories 'Pd', 'Po') to regular hyphens, 3) Removes all hyphens\/minus signs for comparison purposes. This ensures consistent text processing across different Unicode representations of chemical names and formulas, preventing mismatches due to different dash characters (em-dash, en-dash, hyphen-minus, etc.) commonly found in chemical nomenclature."}
{"id":"50fa4016-429d-4320-a927-e2fec1805cec","question":"How does ether0 handle problem categorization in its benchmark?","answer":"ether0 categorizes problems using the `get_problem_category()` function, which splits the problem_type on '\/' and takes the first part. Categories include: functional group, molecule caption, SMILES completion, elucidation, IUPAC name, solubility edit, multiple choice, BBB permeability, Human receptor binding, safety, scent, pKa, LD50, ADME, reaction prediction, retrosynthesis, and molecular formula, among others."}
{"id":"50c72ef5-f62b-4a0a-bec1-dedace7ecb26","question":"How does the async evaluation system work in ether0's QA models?","answer":"The async evaluation system uses `run_grade_eval()` which takes a LiteLLMModel and Ether0OpenAnswer. It constructs prompts with OPEN_ANSWER_PREFIX, gets LLM completions, extracts proposed answers, and calls the async `grade()` method. The main evaluation loop uses `tqdm_asyncio.gather()` to run multiple evaluations in parallel, then calculates accuracy and precision using `MultipleChoiceEvaluation.calculate_accuracy_precision()`."}
{"id":"56cafe76-7189-4072-be98-3773342b3f2f","question":"What are the main packages contained in the ether0 repository?","answer":"The repository contains two main packages: 1) `ether0`: reward functions, rdkit data utilities, dataset generation prompts, dataset data models, language model training prompts, and data models. 2) `ether0.remotes`: server code for ether0 reward functions involving exotic packages and\/or third party models."}
{"id":"9393b392-6150-459f-b95c-b8448fd7217f","question":"How does the is_reasonable_molecule function perform comprehensive molecular validation?","answer":"The `is_reasonable_molecule()` function performs multi-step validation: 1) Always checks valence by calling `SanitizeMol()`, 2) Handles counterions by sorting molecular fragments by size and allowing maximum 2 fragments with small counterions (\u22645 heavy atoms), 3) Extracts the largest fragment as the main molecule, 4) Validates ring systems using `is_reasonable_ring_system()` against a bloom filter, 5) Validates fingerprint patterns using `is_reasonable_fp()`, 6) Optionally excludes reference molecule patterns from validation. Returns False on any validation failure with detailed error reasons."}
{"id":"b9a1d7b4-dd9c-457c-939a-c5c19162aa2c","question":"What is the purpose of ring systems extraction in ether0's molecular processing?","answer":"The `get_ring_system()` function extracts ring systems from RDKit molecules by cleaving bonds that are not in rings and not protected (like ring carbonyls). It returns a list of SMILES representing the individual ring systems. This is used in the `is_reasonable_ring_system()` function to validate whether a molecule's ring systems are found in known, reasonable ring structures using bloom filters."}
{"id":"569266c7-9471-4883-8455-7d7418baea56","question":"How does the LightEval integration work in ether0 and what task types are supported?","answer":"ether0 integrates with LightEval through the `make_ether0_task()` function which creates LightevalTaskConfig objects. The TASKS_TABLE includes general tasks (loose, strict:no_reasoning, strict) and problem type-specific tasks, each with optional soft evaluation. Tasks are configured with custom metrics (ether0_accuracy and ether0_format), prompt functions that convert dataset rows to LightEval Docs, and filtering by problem types. The integration supports both training-time evaluation with format rewards and test-time evaluation with loose XML parsing."}
{"id":"66d71c75-6de4-4b7d-b707-3a747c73a598","question":"How does problem type filtering work in ether0's dataset utilities?","answer":"Problem type filtering uses `make_problem_types_filter()` which supports: 1) Regex patterns (strings starting with 're:') for pattern matching, 2) Exclusion rules (strings starting with '!') to filter out specific types, 3) Exact string matches for inclusion, 4) Single regex or mixed inclusion\/exclusion (but not both). The `filter_problem_types()` function applies these filters to Dataset or DatasetDict objects, automatically detecting the type column ('problem_type' or 'type'). This enables flexible dataset subsetting for training and evaluation on specific problem categories."}
{"id":"cea0ea53-9874-495a-948b-3a36086d0d02","question":"What synthesis constraints are specified in RETRO_PROMPTS?","answer":"RETRO_PROMPTS contains 10 variations for retrosynthetic analysis, specifically constraining syntheses to single steps using commercially available starting materials. Examples include 'Propose a 1-step synthesis for the molecule {smiles} using likely purchasable reactants' and 'Suggest a commercially feasible one-step route to synthesize {smiles}.' This tests practical synthetic planning rather than complex multi-step routes, focusing on accessibility and feasibility."}
{"id":"9daaf353-66f1-4bf2-a351-a766b298bba9","question":"What molecular drawing configuration does ether0 use and what formats are supported?","answer":"ether0's molecular drawing uses specific RDKit configurations: 1) `make_sized_d2d()` creates MolDraw2DCairo objects with default 400x300 dimensions, 2) `draw_molecule()` and `draw_reaction()` support custom background opacity and MolDraw2D objects, 3) Drawing options include black-and-white atom palettes via `useBWAtomPalette()`, 4) Molecules undergo 2D coordinate computation and depiction straightening, 5) Supports both SVG (MolDraw2DSVG) and Cairo (MolDraw2DCairo) output formats. The functions return drawing text strings that can be saved or displayed."}
{"id":"126d8848-221e-4df1-bf52-da16ae0e2fb3","question":"What is the oracle_solubility_eval function and how does it validate molecular edits?","answer":"The `oracle_solubility_eval()` function evaluates whether a proposed molecule meets solubility editing constraints by: 1) Validating the molecule is a single valid SMILES, 2) Checking constraint compliance (scaffold preservation, functional group maintenance, or Tanimoto similarity), 3) Ensuring molecular reasonableness, 4) Using the remote `fetch_solubility()` API to compute actual solubility, 5) Verifying the solubility change is within 0.5 logS units of the target. It returns 1.0 for successful edits and 0.0 for failures, with detailed error reasons stored in metadata."}
{"id":"f817f590-20b3-4c81-b9a6-03c321503f71","question":"How do you set up and run the ether0 remotes server for reward functions?","answer":"First, set the API token environment variable and start the server: `ETHER0_REMOTES_API_TOKEN=abc123 ether0-serve`. Then, set the environment variables for the client: `ETHER0_REMOTES_API_BASE_URL=\"http:\/\/127.0.0.1:8000\" ETHER0_REMOTES_API_TOKEN=abc123`. This server provides access to reward functions that require exotic packages or third-party models."}
{"id":"64df606f-17bf-4b52-8232-1b3a5f5b9297","question":"How does ether0 evaluate model performance on its benchmark?","answer":"ether0 evaluates performance by: 1) Loading the test dataset and adding prompts, 2) Running LLM completions on each problem, 3) Extracting answers using `extract_answer_loose()`, 4) Computing rewards using problem-specific evaluation functions from EVAL_FUNCTIONS, 5) Grouping results by problem category, and 6) Calculating category-wise and overall accuracy metrics. The evaluation supports both accuracy_reward and lower-level reward functions."}
{"id":"45a51270-390c-426b-b2a9-aedcb50b75c1","question":"What is the scope and purpose of SMILES_FROM_FORMULA_PROMPTS in ether0?","answer":"SMILES_FROM_FORMULA_PROMPTS contains 11 prompt variations for generating SMILES structures from molecular formulas without additional constraints. Examples include 'Propose a molecule that has the following formula: {formula}' and 'What is a plausible SMILES for a compound with the formula {formula}?' This tests the model's ability to generate chemically valid structures matching exact atomic compositions, representing the most basic form of structure generation from compositional information."}
{"id":"96d12b3e-6fcf-4749-80a8-05e8eea7eaa5","question":"What are the four XML tag tokens used in ether0's model response formatting?","answer":"The four XML tag tokens are: `THINK_START = \"<|think_start|>\"`, `THINK_END = \"<|think_end|>\"`, `ANSWER_START = \"<|answer_start|>\"`, and `ANSWER_END = \"<|answer_end|>\"`. These tokens surround reasoning and answer content in XML format, with thinking enclosed between THINK_START\/THINK_END and answers enclosed between ANSWER_START\/ANSWER_END."}
{"id":"2aa59126-acb6-455a-b1b3-8d435242c583","question":"What configuration is used for LLM-based answer evaluation in ether0?","answer":"The LLM_SCORE_EVAL_CONFIG uses GPT-4o with temperature 0.0 and a max_score of 1.0. The prompt asks the LLM to grade proposed answers as correct (1.0), incorrect (0.0), or unsure (-1.0) by comparing them to the correct answer. The prompt format includes the question, correct answer, and proposed answer, instructing the model to respond with just the numeric score."}
{"id":"9230a18b-0db6-443d-9e4f-bd776bc402be","question":"How is ORACLE_SOLUBILITY_PROMPTS organized and what are its constraint types?","answer":"ORACLE_SOLUBILITY_PROMPTS is organized as a dictionary with three constraint types: 'tanimoto' (5 prompts) for small changes maintaining similarity, 'scaffold' (5 prompts) for modifications preserving core scaffold, and 'groups' (5 prompts) for changes maintaining specific functional groups. All prompts target approximately 1 logS solubility changes in specified directions, like 'Propose a small change to {smiles} to {direction} its solubility by about 1 logS' with constraint-specific variations."}
{"id":"1cd40ded-26df-4e9f-b825-4b3a6e956d49","question":"What are the main RewardReason enum values used for error classification in ether0?","answer":"The RewardReason enum includes values like: FORMAT_FAILED (invalid XML format), INVALID_MOL (invalid molecule), INVALID_RXN (invalid reaction), WRONG_FORMULA (incorrect molecular formula), FAILED_CONSTRAINT (constraint violations), FAILED_REOS_CHECK (failed molecular reasonableness), FAILED_RING_CHECK (invalid ring systems), NOT_PURCHASABLE (reactants not commercially available), PRODUCT_IS_REACTANT (product appears in reactants), REWARD_FUNCTION_EXCEPTION (unhandled exceptions), and default reasons RIGHT_ANSWER\/WRONG_ANSWER for correct\/incorrect responses."}
{"id":"05775532-e9f3-4a0a-b65a-348106dd4083","question":"How does the tanimoto_similarity function handle edge cases and atom threshold checking?","answer":"The `tanimoto_similarity()` function handles edge cases by: 1) Returning 0.0 if either molecule is None, 2) Computing Morgan fingerprints with radius 2 for both molecules, 3) Applying an atom threshold check that returns 0.0 if the relative difference in heavy atom counts exceeds the threshold (default 10.0 = 1000%, effectively disabled), 4) Using DataStructs.TanimotoSimilarity for the final similarity calculation. The atom threshold prevents false positives when fingerprints are similar but molecules have very different sizes."}
{"id":"08d57902-c74d-4b96-8f87-a5c9f87107e2","question":"How do MOL_FORMULA_PROMPTS incorporate biological context in ether0?","answer":"MOL_FORMULA_PROMPTS (10 variations) combine molecular formulas with biological source organisms to generate biosynthetically plausible structures. Examples include 'A compound with formula {formula} was isolated from {source}. What is a plausible SMILES for it given this organism?' and 'What would be a biologically relevant SMILES for a {formula} compound isolated from the organism {source}?' This approach constrains the chemical space to biologically reasonable compounds."}
{"id":"26374544-cd67-4825-9b79-d0141f7af1d3","question":"How does the extract_thought_answer_strict function validate XML responses?","answer":"The `extract_thought_answer_strict()` function validates XML responses by: 1) Using regex patterns to split text with `maxsplit=1` to enforce exactly one match, 2) Checking that extracted content doesn't contain nested XML tags (no THINK_START in thought\/inter, no ANSWER_START in answer), 3) Ensuring no suffix content exists after the answer, 4) Returning (None, None) for failures including no matches, multiple matches, or nested tags. It handles both reasoning and answer-only modes based on the reasoning parameter."}
{"id":"7aeacc93-688d-4e3e-a922-e2d59f674ab0","question":"What is the purpose of the valid_mol_eval reward function?","answer":"The valid_mol_eval reward function evaluates whether a proposed SMILES completion creates a valid molecule when combined with a partial SMILES string. It returns True if the completion results in a chemically valid molecule, and False otherwise. This is used to assess model-proposed molecular completions in the SMILES completion task."}
{"id":"ff7ab152-c8e8-445b-ae3d-1e4f8d4ef9f3","question":"What is the APPLY_GOOD_MOLECULE_CHECK set and how is it used in accuracy evaluation?","answer":"APPLY_GOOD_MOLECULE_CHECK is a set containing reward function names (`valid_mol_eval`, `formula_eval`, `functional_group_eval`, `sol_eval`) that should check for good molecule quality. When a reward function in this set returns 1.0, the `accuracy_reward()` function: 1) Extracts the full SMILES from metadata, 2) Validates the molecule exists, 3) Checks for bad substructures using `contains_bad_substruct()`, 4) Sets `is_good_molecule` metadata flag, 5) Adds `good_molecule_bonus` to the reward if the molecule passes quality checks. This provides additional reward for chemically reasonable molecules in open-ended generation tasks."}
{"id":"19bb8167-cdd7-435a-aae0-d807d9aa4928","question":"What character and language validation does ether0 perform on text input?","answer":"ether0 validates text using two regex patterns: 1) `invalid_chars_regex` allows Latin letters, Greek letters, subscripts\/superscripts, numbers, and common punctuation while rejecting other characters, 2) `invalid_languages_regex` rejects 25 non-Latin scripts including Arabic, Cyrillic, Han, Hiragana, etc. The `contains_invalid()` function checks both character and language validity with configurable thresholds, returning a boolean and list of invalid matches. This helps filter out non-chemical text content during dataset processing."}
{"id":"86f9f930-d5f9-4611-87a3-221431d736a1","question":"What are the main differences between product_eval and caption_eval functions?","answer":"Both `product_eval()` and `caption_eval()` use similar logic but differ in metadata handling: 1) `product_eval()` computes Tanimoto similarity (soft mode) or exact match (hard mode) between the largest molecules from two SMILES strings, 2) `caption_eval()` forwards to `product_eval()` but additionally stores the Tanimoto similarity in metadata regardless of mode, 3) Both handle invalid molecules by returning 0.0, 4) Both use `get_largest_mol()` to extract main molecules and ignore small fragments. The caption eval provides extra similarity metrics for analysis."}
{"id":"54103c07-66f9-4795-937d-9568855cb3af","question":"What are the three ProblemPrompt enum values and what do they return?","answer":"The three ProblemPrompt enum values are: 1) `NONE`: Returns an empty string, adding no additional prompt. 2) `THINK_ANSWER`: Returns the REASONING_ANSWER prompt text that instructs the model to provide both reasoning and answer with XML tags. 3) `ANSWER`: Returns the ANSWER_ONLY prompt text that instructs the model to provide only the answer with XML tags. These are used to configure how problems are presented to the model during training."}
{"id":"3e0b0249-f982-42a6-8f61-99f1c41bdc4b","question":"How does the ChatArguments class handle batched vs single problem formatting?","answer":"ChatArguments handles batched vs single problems by checking if `row[\"problem\"]` is a string or list. For single problems: it creates one conversation with the problem string. For batched problems: it creates a list of conversations, one for each problem in the list. The same logic applies to answers and thoughts in SFT conversations, using `zip(row[\"answer\"], row[\"thought\"], msgs, strict=True)` with `starmap()` to create multiple assistant responses. This allows efficient processing of both individual and batch training examples."}
{"id":"88020fb1-b9ec-4901-b598-5f7dc04038ca","question":"What is the structure of the Ether0OpenAnswer class used for evaluation?","answer":"Ether0OpenAnswer extends MultipleChoiceQuestion with specific configurations: prompt_without_id=True, prompt_without_options=True, empty options list, and optional unsure_answer. It has a `from_ds()` class method to create instances from dataset rows and an async `grade()` method that uses LLM scoring to evaluate proposed answers against ideal answers, returning CORRECT, INCORRECT, or UNSURE evaluations."}
{"id":"d786a56a-904c-46ca-b3e7-20bc6f6910a6","question":"What is the mol_from_smiles function and why is it needed?","answer":"The `mol_from_smiles()` function is a wrapper around RDKit's `MolFromSmiles()` that correctly handles the type annotation issue. While `MolFromSmiles` is type-hinted to always return a Mol object, it can actually return None for invalid SMILES. This wrapper function makes the None return type explicit, providing better type safety for downstream code."}
{"id":"7d5012d3-21e4-4dbe-b6fa-ccf5ef2f8040","question":"How do you install ether0 from GitHub?","answer":"You can install ether0 from GitHub using pip with the command: `pip install git+https:\/\/github.com\/Future-House\/ether0.git`. Alternatively, for a full setup, clone the repo and use uv: `git clone https:\/\/github.com\/Future-House\/ether0.git && cd ether0 && uv sync`"}
{"id":"11b2ac0a-f931-45b2-946e-90a4d3825840","question":"How are chemical reaction prompts structured in ether0's problem templates?","answer":"ether0 includes two types of reaction prompts: REACTION_PROMPTS (10 variations) for predicting reaction products given reactants, using formats like 'What is the product of this reaction? {rxn_smiles}', and NAME_REACTION_PROMPTS (10 variations) for identifying reaction names, asking 'What is the name of this reaction?\\n{rxn_smiles}'. Both use reaction SMILES format and provide multiple phrasings for robust evaluation."}
{"id":"0a4777d5-5e4f-4d71-b099-379f048ad79e","question":"What is the difference between strict and loose XML answer extraction patterns in ether0?","answer":"Strict patterns (`STRICT_XML_ANSWER_SPLIT_PATTERNS`) are used for ether0 models that have been trained to comply with exact XML formatting, requiring precise tag placement and no extra content. Loose patterns (`LOOSE_XML_ANSWER_LOOSE_PATTERN`) are used for other models, allowing extra whitespace, preceding\/trailing text, and multiple answer tags (keeping the last one). Loose patterns are more permissive to maximize performance with models that weren't trained on the specific XML format."}
{"id":"e53d1d6d-f539-4774-9b02-419dd8d161bf","question":"How does the SysPrompt enum work and what system prompts are available?","answer":"The SysPrompt enum defines available system prompts with `SCIENTIFIC_AI = \"scientific_ai\"` as the only current option. The `get_sys_prompt()` method returns \"You are a scientific reasoning AI assistant.\" for the SCIENTIFIC_AI case. The enum uses Enum instead of StrEnum for trl.TrlParser compatibility. This system provides a structured way to define and retrieve system prompts for different conversation contexts in model training and evaluation."}
{"id":"acf23cfd-1f04-4b7a-9fee-190d5d6fe597","question":"What are the key features of ether0's molecular drawing functionality?","answer":"The molecular drawing functions include: `draw_molecule()` for single molecules and `draw_reaction()` for chemical reactions. Both support custom background opacity and MolDraw2D objects. They use RDKit to compute 2D coordinates, straighten depictions, apply black-and-white atom palettes, and return SVG or Cairo drawings. The functions handle molecule sanitization and coordinate optimization for clear visualization."}
{"id":"c2fe1c02-c69e-40a1-a083-36d136bfdf8b","question":"What license does the ether0 package have?","answer":"The repo is licensed as Apache 2.0, copyright 2025 under FutureHouse."}
